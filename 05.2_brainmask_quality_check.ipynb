{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94cda0",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to look at specific images for which the brain mask ended up looking wrong (by visual inspection) and to tweak parameters to get it right. The script `05.1_dti_fit.py` was run first to generate a family of brain masks, DTI fits, and FA images.\n",
    "\n",
    "This notebook concludes that using bvalue=0 images only makes sense for computing brain mask.\n",
    "\n",
    "This notebook also looks into the option of using my GPU implementation of brain masking. The memory limitation makes it hard to use a large filter, but the speed makes it cheap to run the filter many times. This approach seems to have the best results in the end.\n",
    "\n",
    "It's also faster in a sense, but not practically. Computing one brain mask with GPU is much faster than CPU, but if you have a large dataset then you can typically process the images in parallel with CPU but GPU memory limitations will make that harder to do with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a72721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dipy.io.image\n",
    "import dipy.io\n",
    "import dipy.core.gradients\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7490849",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'DMRI_EXTRACTED_NONTEST/'\n",
    "img_dirs = glob.glob(os.path.join(data_dir,'*ABCD-MPROC-DTI*/sub-*/ses-*/dwi/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_fmriresults01_df = pd.read_csv('01.1_abcd_sample2/sampled_nontest_fmriresults01.csv')\n",
    "sampled_fmriresults01_df['dirname'] = sampled_fmriresults01_df.derived_files.apply(lambda x : x.split('/')[-1].strip('.tgz'))\n",
    "dirname_to_full_path = {img_dir.split('/')[-5]:img_dir for img_dir in img_dirs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for (subjectkey,interview_age),df in sampled_fmriresults01_df.groupby(['subjectkey', 'interview_age']):\n",
    "    paths = []\n",
    "    for _,row in df.iterrows():\n",
    "        if row.dirname not in dirname_to_full_path.keys():\n",
    "            raise FileNotFoundError(f\"Could not find a directory for fmriresults01 id {row.fmriresults01_id}\")\n",
    "        img_dir = dirname_to_full_path[row.dirname]\n",
    "        dwi_path = glob.glob(os.path.join(img_dir, '*.nii'))[0]\n",
    "        bval_path = glob.glob(os.path.join(img_dir, '*.bval'))[0]\n",
    "        bvec_path = glob.glob(os.path.join(img_dir, '*.bvec'))[0]\n",
    "        paths.append({\n",
    "            'img_dir' : img_dir,\n",
    "            'dwi_path' : dwi_path,\n",
    "            'bval_path' : bval_path,\n",
    "            'bvec_path' : bvec_path,\n",
    "        })\n",
    "    data.append({\n",
    "        'paths' : paths,\n",
    "\n",
    "        'subjectkey' : row.subjectkey,\n",
    "        'interview_age' : row.interview_age,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f6dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this to look at the number of bvals for each image, alongside subject id and interview age\n",
    "\n",
    "for d in data:\n",
    "    for i,p in enumerate(d['paths']):\n",
    "        bvals, bvecs = dipy.io.read_bvals_bvecs(p['bval_path'], p['bvec_path'])\n",
    "        print(f\"{len(bvals)} \\t {d['subjectkey']} \\t {d['interview_age']}\",\n",
    "              f\"(part {i+1} of {len(d['paths'])})\" if len(d['paths'])>1 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from one of the dictionaries listed in the object \"data\" defined above\n",
    "def load_data(d):\n",
    "    img_data_list =[]\n",
    "    bvals_list = []\n",
    "    bvecs_list = []\n",
    "    prev_affine_transform = None\n",
    "\n",
    "    for p in d['paths']:\n",
    "        img_data, affine = dipy.io.image.load_nifti(p['dwi_path'])\n",
    "        assert((prev_affine_transform is None) or (affine==prev_affine_transform).all())\n",
    "        prev_affine_transform = affine  \n",
    "        bvals, bvecs = dipy.io.read_bvals_bvecs(p['bval_path'], p['bvec_path'])\n",
    "        img_data_list.append(img_data)\n",
    "        bvals_list.append(bvals)\n",
    "        bvecs_list.append(bvecs)\n",
    "        bvals = np.concatenate(bvals_list)\n",
    "    img_data = np.concatenate(img_data_list, axis=-1)\n",
    "    bvecs = np.concatenate(bvecs_list, axis=0)\n",
    "    gtab = dipy.core.gradients.gradient_table(bvals, bvecs)\n",
    "    return img_data, affine, gtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a57a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_indexed_by_subject = {d['subjectkey']:d for d in data}\n",
    "\n",
    "d_random = random.choice(data) # Pick a random one\n",
    "\n",
    "# pick ones for which the brain mask was observed problematic\n",
    "d_badmask1 = data_indexed_by_subject['NDAR_INV87T95RHP']\n",
    "d_badmask2 = data_indexed_by_subject['NDAR_INVE0KZKF5V']\n",
    "d_badmask3 = data_indexed_by_subject['NDAR_INVGL5PNTK7']\n",
    "d_badmask4 = data_indexed_by_subject['NDAR_INVWAC9RH98']\n",
    "\n",
    "img_data, affine, gtab = load_data(d_badmask1) # Load one to demonstrate how we process it below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e322f",
   "metadata": {},
   "source": [
    "Generate brain mask and preview it for the loaded image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a292188",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = range(img_data.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8600dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(img):\n",
    "    fig,axs = plt.subplots(1,3,figsize=(10,5))\n",
    "    axs[0].imshow(img[62,:,:].T, origin='lower', cmap='gray')\n",
    "    axs[1].imshow(img[:,:,80].T, origin='lower', cmap='gray')\n",
    "    axs[2].imshow(img[:,75,:].T, origin='lower', cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611813df",
   "metadata": {},
   "source": [
    "Try again with different parameters on the otsu thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d120da",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = [0], median_radius=4, numpass=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e130595",
   "metadata": {},
   "source": [
    "In the end, instead of tweaking the median filtering, it seems that focusing on the image for a specific bvalue, rather than all bvalues, helped the most. Picking the bvalue that has the least noisy image for mask generation seems to be the way to go. Let's inspect if there's a consistent best b-value for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, affine, gtab = load_data(random.choice(data)) # Load random subject\n",
    "num_bvals = img_data.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in np.unique(gtab.bvals):\n",
    "    i = random.choice(np.where(gtab.bvals==b)[0])\n",
    "    print(f\"Image with bvalue {gtab.bvals[i]}:\")\n",
    "    preview(img_data[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77f06a",
   "metadata": {},
   "source": [
    "Running this cell a few times, the b-value 0 images (i.e. the ones that aren't diffusion weighted are clearly best to use for masking. This makes sense, because\n",
    "\n",
    "> image contrast increases at higher b-values, albeit at the cost of reduced SNR\n",
    "\n",
    "(from https://doi.org/10.1016/B978-0-12-817057-1.00022-6)\n",
    "\n",
    "and while SNR and contrast both matter for accuracy of otsu thresholding-- here it's SNR that is our limiting factor, rather than contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1cf80",
   "metadata": {},
   "source": [
    "Let's now try using bval 0 only in the mask generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, affine, gtab = load_data(d_badmask1) # Load one to demonstrate how we process it below\n",
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = np.where(gtab.bvals==0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5099e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8808e8",
   "metadata": {},
   "source": [
    "Ah but here's one that the b=0 based masking seems to perform worse on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa339f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, affine, gtab = load_data(data_indexed_by_subject['NDAR_INV761E1JVD']) # Load one to demonstrate how we process it below\n",
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = np.where(gtab.bvals==0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8ebcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for b in np.unique(gtab.bvals):\n",
    "    i = random.choice(np.where(gtab.bvals==b)[0])\n",
    "    print(f\"Image with bvalue {gtab.bvals[i]}:\")\n",
    "    preview(img_data[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c5ede",
   "metadata": {},
   "source": [
    "In this case the higher SNR of the b=0 images is harmful for otsu thresholding, because it emphasizes a non-brain structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2473383",
   "metadata": {},
   "source": [
    "Perhaps a larger median filter can ignore such structures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, affine, gtab = load_data(data_indexed_by_subject['NDAR_INV761E1JVD']) # Load one to demonstrate how we process it below\n",
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = np.where(gtab.bvals==0)[0], median_radius=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a317b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780fa8b",
   "metadata": {},
   "source": [
    "But a radius 7 median filter just takes so long.\n",
    "\n",
    "Below is a different approach where I set up a GPU version of median filtering.\n",
    "This runs a LOT faster, but is limited by GPU memory. With my 8GB card the highest `mean_radius` I can do is 3. However we can increase `numpass` very cheaply, because each run of the filter is extremely fast. Check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece511ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainmask_with_gpu import median_otsu_gpu\n",
    "img_data, affine, gtab = load_data(data_indexed_by_subject['NDAR_INV761E1JVD']) # Load one to demonstrate how we process it below\n",
    "img_data_masked, mask = median_otsu_gpu(img_data, vol_idx = np.where(gtab.bvals==0)[0], median_radius=2, numpass=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13591709",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bvals = img_data.shape[3]\n",
    "i = random.randint(0,num_bvals-1)\n",
    "i=0\n",
    "preview(img_data[:,:,:,i])\n",
    "preview(mask)\n",
    "preview(img_data_masked[:,:,:,i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
