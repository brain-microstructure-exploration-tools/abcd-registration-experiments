{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94cda0",
   "metadata": {},
   "source": [
    "GradICON deformable registration of FA images. (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a72721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "import footsteps\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7490849",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_dir = 'dti_fit_images/fa'\n",
    "data = [{\"fa\":path, \"filename\":os.path.basename(path)} for path in glob.glob(os.path.join(fa_dir,'*'))]\n",
    "data_train, data_valid = monai.data.utils.partition_dataset(data, ratios=(8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transforms = [\n",
    "    monai.transforms.LoadImageD(keys=\"fa\"),\n",
    "    monai.transforms.AddChannelD(keys=\"fa\"),\n",
    "    # The input images are known (140,140,140); we pad out to 144 in each dim\n",
    "    monai.transforms.SpatialPadD(keys=\"fa\", spatial_size=(144,144,144), mode=\"constant\"),\n",
    "    monai.transforms.ToTensorD(keys=\"fa\"),\n",
    "    monai.transforms.ToDeviceD(keys=\"fa\", device=device),\n",
    "]\n",
    "\n",
    "transform = monai.transforms.Compose(base_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59375d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the overall scale of affine transform\n",
    "a=0.1\n",
    "\n",
    "spatial_size = transform(data[0])['fa'].shape[1:]\n",
    "S = spatial_size[0]\n",
    "\n",
    "rand_affine_params = {\n",
    "    'prob':1.,\n",
    "    'mode': 'bilinear',\n",
    "    'padding_mode': 'zeros',\n",
    "    'spatial_size':spatial_size,\n",
    "    'cache_grid':True,\n",
    "    'rotate_range': (a*np.pi/2,)*3,\n",
    "    'shear_range': (0,)*6, # no shearing\n",
    "    'translate_range': (a*S/16,)*3,\n",
    "    'scale_range': (a*0.4,)*3,\n",
    "}\n",
    "\n",
    "rand_affine_transform = monai.transforms.RandAffineD(keys='fa', **rand_affine_params)\n",
    "\n",
    "transform_train = monai.transforms.Compose(base_transforms + [rand_affine_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206482e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train = monai.data.CacheDataset(data_train, transform_train)\n",
    "ds_valid = monai.data.CacheDataset(data_valid, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e54a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = monai.networks.blocks.Warp(mode=\"bilinear\", padding_mode=\"zeros\")\n",
    "\n",
    "def mse_loss(b1, b2):\n",
    "    \"\"\"Return image similarity loss given two batches b1 and b2 of shape (batch_size, channels, H,W,D).\n",
    "    It is scaled up a bit here.\"\"\"\n",
    "    return 10000*((b1-b2)**2).mean()\n",
    "\n",
    "def ncc_loss(b1, b2):\n",
    "    \"\"\"Return the negative NCC loss given two batches b1 and b2 of shape (batch_size, channels, H,W,D).\n",
    "    It is averaged over batches and channels.\"\"\"\n",
    "    mu1 = b1.mean(dim=(2,3,4)) # means\n",
    "    mu2 = b2.mean(dim=(2,3,4))\n",
    "    alpha1 = (b1**2).mean(dim=(2,3,4)) # second moments\n",
    "    alpha2 = (b2**2).mean(dim=(2,3,4))\n",
    "    alpha12 = (b1*b2).mean(dim=(2,3,4)) # cross term\n",
    "    numerator = alpha12 - mu1*mu2\n",
    "    denominator = torch.sqrt((alpha1 - mu1**2) * (alpha2-mu2**2))\n",
    "    ncc = numerator / denominator\n",
    "    return -ncc.mean() # average over batches and channels\n",
    "\n",
    "def compose_ddf(u,v):\n",
    "    \"\"\"Compose two displacement fields, return the displacement that warps by v followed by u\"\"\"\n",
    "    return u + warp(v,u)\n",
    "\n",
    "_, H, W, D = ds_train[0]['fa'].shape\n",
    "\n",
    "# Compute discrete spatial derivatives\n",
    "def diff_and_trim(array, axis):\n",
    "    \"\"\"Take the discrete difference along a spatial axis, which should be 2,3, or 4.\n",
    "    Return a difference tensor with all spatial axes trimmed by 1.\"\"\"\n",
    "    return torch.diff(array, axis=axis)[:, :, :(H-1), :(W-1), :(D-1)]\n",
    "\n",
    "def size_of_spatial_derivative(u):\n",
    "    \"\"\"Return the squared Frobenius norm of the spatial derivative of the given displacement field.\n",
    "    To clarify, this is about the derivative of the actual displacement field map, not the deformation\n",
    "    that the displacement field map defines. The expected input shape is (batch,3,H,W,D).\n",
    "    Output shape is (batch).\"\"\"\n",
    "    dx = diff_and_trim(u, 2)\n",
    "    dy = diff_and_trim(u, 3)\n",
    "    dz = diff_and_trim(u, 4)\n",
    "    return(dx**2 + dy**2 + dz**2).sum(axis=1).mean(axis=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelOutput = namedtuple(\"ModelOutput\", \"all_loss, sim_loss, gradicon_loss, deformation_AB\")\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, lambda_reg, compute_sim_loss):\n",
    "        super().__init__()\n",
    "        self.reg_net = monai.networks.nets.UNet(\n",
    "            3,  # spatial dims\n",
    "            2,  # input channels (one for fixed image and one for moving image)\n",
    "            3,  # output channels (to represent 3D displacement vector field)\n",
    "            (32, 32, 32, 32, 64),  # channel sequence\n",
    "            (2, 2, 2, 2),  # convolutional strides\n",
    "            dropout=0.2,\n",
    "            norm=\"batch\"\n",
    "        )\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.compute_sim_loss = compute_sim_loss\n",
    "    \n",
    "    def update_lambda_reg(self, new_lambda_reg):\n",
    "        self.lambda_reg = new_lambda_reg\n",
    "\n",
    "    def forward(self, img_A, img_B) -> ModelOutput:\n",
    "        img_pair_AB = torch.cat((img_A, img_B), dim=1)\n",
    "        img_pair_BA = img_pair_AB[:,[1,0]]\n",
    "\n",
    "        deformation_AB = self.reg_net(img_pair_AB) # deforms img_B to the space of img_A\n",
    "        deformation_BA = self.reg_net(img_pair_BA) # deforms img_A to the space of img_B\n",
    "\n",
    "        img_B_warped = warp(img_B, deformation_AB)\n",
    "        img_A_warped = warp(img_A, deformation_BA)\n",
    "        sim_loss_A = self.compute_sim_loss(img_A, img_B_warped)\n",
    "        sim_loss_B = self.compute_sim_loss(img_B, img_A_warped)\n",
    "        composite_deformation_A = compose_ddf(deformation_AB, deformation_BA)\n",
    "        composite_deformation_B = compose_ddf(deformation_BA, deformation_AB)\n",
    "        gradicon_loss_A = size_of_spatial_derivative(composite_deformation_A).mean()\n",
    "        gradicon_loss_B = size_of_spatial_derivative(composite_deformation_B).mean()\n",
    "        \n",
    "        sim_loss = sim_loss_A + sim_loss_B\n",
    "        gradicon_loss = gradicon_loss_A + gradicon_loss_B\n",
    "        \n",
    "        return ModelOutput(\n",
    "            all_loss = sim_loss + self.lambda_reg * gradicon_loss,\n",
    "            sim_loss = sim_loss,\n",
    "            gradicon_loss = gradicon_loss,\n",
    "            deformation_AB = deformation_AB\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaa119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCurves:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "        \n",
    "        self.epochs =[]\n",
    "        self.all_losses = []\n",
    "        self.sim_losses = []\n",
    "        self.gradicon_losses = []\n",
    "        \n",
    "        self.clear_buffers()\n",
    "        \n",
    "    def clear_buffers(self):\n",
    "        self.all_losses_buffer = []\n",
    "        self.sim_losses_buffer = []\n",
    "        self.gradicon_losses_buffer = []\n",
    "        \n",
    "    def add_to_buffer(self, model_output : ModelOutput):\n",
    "        self.all_losses_buffer.append(model_output.all_loss.item())\n",
    "        self.sim_losses_buffer.append(model_output.sim_loss.item())\n",
    "        self.gradicon_losses_buffer.append(model_output.gradicon_loss.item())\n",
    "        \n",
    "    def aggregate_buffers_for_epoch(self, epoch : int):\n",
    "        self.epochs.append(epoch)\n",
    "        self.all_losses.append(np.mean(self.all_losses_buffer))\n",
    "        self.sim_losses.append(np.mean(self.sim_losses_buffer))\n",
    "        self.gradicon_losses.append(np.mean(self.gradicon_losses_buffer))\n",
    "        self.clear_buffers()\n",
    "        \n",
    "    def plot(self, savepath=None):\n",
    "        fig, axs = plt.subplots(1,3,figsize = (15,5))\n",
    "        axs[0].plot(self.epochs, self.all_losses)\n",
    "        axs[0].set_title(f\"{self.name}: overall loss\")\n",
    "        axs[1].plot(self.epochs, self.sim_losses)\n",
    "        axs[1].set_title(f\"{self.name}: similarity loss\")\n",
    "        axs[2].plot(self.epochs, self.gradicon_losses, label=\"gradicon loss\")\n",
    "        axs[2].set_title(f\"{self.name}: gradicon loss\")\n",
    "        for ax in axs:\n",
    "            ax.set_xlabel(\"epoch\")\n",
    "        if savepath is not None:\n",
    "            plt.savefig(savepath)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncc_loss = monai.losses.LocalNormalizedCrossCorrelationLoss(\n",
    "    spatial_dims=3,\n",
    "    kernel_size=5,\n",
    "    smooth_nr = 0,\n",
    "    smooth_dr = 1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = monai.data.DataLoader(ds_train, shuffle=True, batch_size=1, drop_last=True)\n",
    "dl_valid = monai.data.DataLoader(ds_valid, shuffle=True, batch_size=2, drop_last=True)\n",
    "max_epochs = 300\n",
    "validate_when = lambda e : ((e%2==0) and (e!=0)) or (e==max_epochs-1)\n",
    "lambda_reg_rate_of_increase = 0.001 # How much to increase lambda_reg per epoch.\n",
    "model = Model(\n",
    "    lambda_reg = 0,\n",
    "    compute_sim_loss = ncc_loss\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# min_lr=1e-5\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.954992586)\n",
    "loss_curves_train = LossCurves(\"training\")\n",
    "loss_curves_valid = LossCurves(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e309a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(max_epochs):\n",
    "#     current_lr = scheduler.get_last_lr()[0]\n",
    "    current_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(f'Epoch {e+1}/{max_epochs} (LR = {current_lr:.1e}, lambda_reg = {model.lambda_reg:.1e}):')\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    dl_train_iter = iter(dl_train)\n",
    "    while True:\n",
    "        try:\n",
    "            b1 = next(dl_train_iter)\n",
    "            b2 = next(dl_train_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(b1['fa'], b2['fa'])\n",
    "        model_output.all_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_curves_train.add_to_buffer(model_output)\n",
    "        del(model_output)\n",
    "\n",
    "#     if scheduler.get_last_lr()[0] > min_lr:\n",
    "#         scheduler.step()\n",
    "\n",
    "    loss_curves_train.aggregate_buffers_for_epoch(e)\n",
    "    print(f\"\\tTraining loss: {loss_curves_train.all_losses[-1]:.4f} ({loss_curves_train.sim_losses[-1]:.4f},{loss_curves_train.gradicon_losses[-1]:.4f})\")\n",
    "    \n",
    "    # Validate\n",
    "    if validate_when(e):\n",
    "        model.eval()\n",
    "        dl_valid_iter = iter(dl_valid)\n",
    "        while True:\n",
    "            try:\n",
    "                b1 = next(dl_valid_iter)\n",
    "                b2 = next(dl_valid_iter)\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model_output = model(b1['fa'], b2['fa'])\n",
    "                loss_curves_valid.add_to_buffer(model_output)\n",
    "        loss_curves_valid.aggregate_buffers_for_epoch(e) \n",
    "        print(\"\\tValidation loss:\", loss_curves_valid.all_losses[-1])\n",
    "    \n",
    "    model.update_lambda_reg(model.lambda_reg + lambda_reg_rate_of_increase)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "\n",
    "loss_curves_train.plot(savepath = footsteps.output_dir + 'loss_plot_train.png')\n",
    "loss_curves_valid.plot(savepath = footsteps.output_dir + 'loss_plot_valid.png')\n",
    "\n",
    "with open(footsteps.output_dir + 'loss_curves.p', 'wb') as f:\n",
    "    pickle.dump([loss_curves_train, loss_curves_valid],f)\n",
    "\n",
    "torch.save(model.state_dict(), footsteps.output_dir + 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "\n",
    "model.load_state_dict(torch.load(footsteps.output_dir + 'model_state_dict.pth'))\n",
    "\n",
    "with open(footsteps.output_dir + 'loss_curves.p', 'rb') as f:\n",
    "    loss_curves_train, loss_curves_valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42565b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "# change ds_valid to ds_train to view performance on training data\n",
    "d1 = random.choice(ds_valid)\n",
    "d2 = random.choice(ds_valid)\n",
    "\n",
    "img_A = d1['fa'].unsqueeze(0)\n",
    "img_B = d2['fa'].unsqueeze(0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output = model(img_A,img_B)\n",
    "\n",
    "img_B_warped = warp(img_B, model_output.deformation_AB)\n",
    "\n",
    "preview_slices = (80,80,80)\n",
    "\n",
    "print(\"moving:\")\n",
    "util.preview_image(img_B[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"warped moving:\")\n",
    "util.preview_image(img_B_warped[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"target:\")\n",
    "util.preview_image(img_A[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"checkerboard of warped moving and target:\")\n",
    "util.preview_checkerboard(img_A[0,0].cpu(), img_B_warped[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"deformation vector field:\")\n",
    "util.preview_3D_vector_field(model_output.deformation_AB[0].cpu(), slices=preview_slices)\n",
    "print(\"deformed grid:\")\n",
    "util.preview_3D_deformation(model_output.deformation_AB[0].cpu(),5, slices=preview_slices)\n",
    "print(\"jacobian determinant:\")\n",
    "det = util.jacobian_determinant(model_output.deformation_AB[0].cpu())\n",
    "util.preview_image(det, normalize_by='slice', threshold=0, slices=preview_slices)\n",
    "print(\"sim loss:\", model_output.sim_loss.item())\n",
    "print(\"gradicon loss:\", model_output.gradicon_loss.item())\n",
    "print(\"overall loss:\", model_output.all_loss.item())\n",
    "num_folds = (det<0).sum()\n",
    "print(\"Number of folds:\", num_folds, f\"(folding rate {100*num_folds/np.prod(det.shape)}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bb66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
