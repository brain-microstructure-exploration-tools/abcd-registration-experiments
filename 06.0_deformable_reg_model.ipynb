{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94cda0",
   "metadata": {},
   "source": [
    "GradICON deformable registration of FA images. (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a72721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "import footsteps\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7490849",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_dir = 'dti_fit_images/fa'\n",
    "data = [{\"fa\":path, \"filename\":os.path.basename(path)} for path in glob.glob(os.path.join(fa_dir,'*'))]\n",
    "data_train, data_valid = monai.data.utils.partition_dataset(data, ratios=(8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImageD(keys=\"fa\"),\n",
    "    monai.transforms.AddChannelD(keys=\"fa\"),\n",
    "    # The input images are known (140,140,140); we pad out to 144 in each dim\n",
    "    monai.transforms.SpatialPadD(keys=\"fa\", spatial_size=(144,144,144), mode=\"constant\"),\n",
    "    monai.transforms.ToTensorD(keys=\"fa\"),\n",
    "    monai.transforms.ToDeviceD(keys=\"fa\", device=device),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206482e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train = monai.data.CacheDataset(data_train, transform)\n",
    "ds_valid = monai.data.CacheDataset(data_valid, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e54a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = monai.networks.blocks.Warp(mode=\"bilinear\", padding_mode=\"zeros\")\n",
    "\n",
    "def mse_loss(b1, b2):\n",
    "    \"\"\"Return image similarity loss given two batches b1 and b2 of shape (batch_size, channels, H,W,D)\n",
    "    It is scaled up a bit here.\"\"\"\n",
    "    return 10000*((b1-b2)**2).mean()\n",
    "\n",
    "def compose_ddf(u,v):\n",
    "    \"\"\"Compose two displacement fields, return the displacement that warps by v followed by u\"\"\"\n",
    "    return u + warp(v,u)\n",
    "\n",
    "_, H, W, D = ds_train[0]['fa'].shape\n",
    "\n",
    "# Compute discrete spatial derivatives\n",
    "def diff_and_trim(array, axis):\n",
    "    \"\"\"Take the discrete difference along a spatial axis, which should be 2,3, or 4.\n",
    "    Return a difference tensor with all spatial axes trimmed by 1.\"\"\"\n",
    "    return torch.diff(array, axis=axis)[:, :, :(H-1), :(W-1), :(D-1)]\n",
    "\n",
    "def size_of_spatial_derivative(u):\n",
    "    \"\"\"Return the squared Frobenius norm of the spatial derivative of the given displacement field.\n",
    "    To clarify, this is about the derivative of the actual displacement field map, not the deformation\n",
    "    that the displacement field map defines. The expected input shape is (batch,3,H,W,D).\n",
    "    Output shape is (batch).\"\"\"\n",
    "    dx = diff_and_trim(u, 2)\n",
    "    dy = diff_and_trim(u, 3)\n",
    "    dz = diff_and_trim(u, 4)\n",
    "    return(dx**2 + dy**2 + dz**2).sum(axis=1).mean(axis=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelOutput = namedtuple(\"ModelOutput\", \"all_loss, sim_loss, gradicon_loss, deformation_AB\")\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, lambda_reg, compute_sim_loss):\n",
    "        super().__init__()\n",
    "        self.reg_net = monai.networks.nets.UNet(\n",
    "            3,  # spatial dims\n",
    "            2,  # input channels (one for fixed image and one for moving image)\n",
    "            3,  # output channels (to represent 3D displacement vector field)\n",
    "            (32, 32, 32, 32, 64),  # channel sequence\n",
    "            (2, 2, 2, 2),  # convolutional strides\n",
    "            dropout=0.2,\n",
    "            norm=\"batch\"\n",
    "        )\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.compute_sim_loss = compute_sim_loss\n",
    "\n",
    "    def forward(self, img_A, img_B) -> ModelOutput:\n",
    "        img_pair_AB = torch.cat((img_A, img_B), dim=1)\n",
    "        img_pair_BA = img_pair_AB[:,[1,0]]\n",
    "\n",
    "        deformation_AB = self.reg_net(img_pair_AB) # deforms img_B to the space of img_A\n",
    "        deformation_BA = self.reg_net(img_pair_BA) # deforms img_A to the space of img_B\n",
    "\n",
    "        img_B_warped = warp(img_B, deformation_AB)\n",
    "        img_A_warped = warp(img_A, deformation_BA)\n",
    "        sim_loss_A = self.compute_sim_loss(img_A, img_B_warped)\n",
    "        sim_loss_B = self.compute_sim_loss(img_B, img_A_warped)\n",
    "        composite_deformation_A = compose_ddf(deformation_AB, deformation_BA)\n",
    "        composite_deformation_B = compose_ddf(deformation_BA, deformation_AB)\n",
    "        gradicon_loss_A = size_of_spatial_derivative(composite_deformation_A).mean()\n",
    "        gradicon_loss_B = size_of_spatial_derivative(composite_deformation_B).mean()\n",
    "        \n",
    "        sim_loss = sim_loss_A + sim_loss_B\n",
    "        gradicon_loss = gradicon_loss_A + gradicon_loss_B\n",
    "        \n",
    "        return ModelOutput(\n",
    "            all_loss = sim_loss + self.lambda_reg * gradicon_loss,\n",
    "            sim_loss = sim_loss,\n",
    "            gradicon_loss = gradicon_loss,\n",
    "            deformation_AB = deformation_AB\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaa119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCurves:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "        \n",
    "        self.epochs =[]\n",
    "        self.all_losses = []\n",
    "        self.sim_losses = []\n",
    "        self.gradicon_losses = []\n",
    "        \n",
    "        self.clear_buffers()\n",
    "        \n",
    "    def clear_buffers(self):\n",
    "        self.all_losses_buffer = []\n",
    "        self.sim_losses_buffer = []\n",
    "        self.gradicon_losses_buffer = []\n",
    "        \n",
    "    def add_to_buffer(self, model_output : ModelOutput):\n",
    "        self.all_losses_buffer.append(model_output.all_loss.item())\n",
    "        self.sim_losses_buffer.append(model_output.sim_loss.item())\n",
    "        self.gradicon_losses_buffer.append(model_output.gradicon_loss.item())\n",
    "        \n",
    "    def aggregate_buffers_for_epoch(self, epoch : int):\n",
    "        self.epochs.append(epoch)\n",
    "        self.all_losses.append(np.mean(self.all_losses_buffer))\n",
    "        self.sim_losses.append(np.mean(self.sim_losses_buffer))\n",
    "        self.gradicon_losses.append(np.mean(self.gradicon_losses_buffer))\n",
    "        self.clear_buffers()\n",
    "        \n",
    "    def plot(self, savepath=None):\n",
    "        fig, axs = plt.subplots(1,3,figsize = (15,5))\n",
    "        axs[0].plot(self.epochs, self.all_losses)\n",
    "        axs[0].set_title(f\"{self.name}: overall loss\")\n",
    "        axs[1].plot(self.epochs, self.sim_losses)\n",
    "        axs[1].set_title(f\"{self.name}: similarity loss\")\n",
    "        axs[2].plot(self.epochs, self.gradicon_losses, label=\"gradicon loss\")\n",
    "        axs[2].set_title(f\"{self.name}: gradicon loss\")\n",
    "        for ax in axs:\n",
    "            ax.set_xlabel(\"epoch\")\n",
    "        if savepath is not None:\n",
    "            plt.savefig(savepath)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc215b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncc_loss = monai.losses.LocalNormalizedCrossCorrelationLoss(\n",
    "    spatial_dims=3,\n",
    "    kernel_size=5,\n",
    "    smooth_nr = 0,\n",
    "    smooth_dr = 1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = monai.data.DataLoader(ds_train, shuffle=True, batch_size=1, drop_last=True)\n",
    "dl_valid = monai.data.DataLoader(ds_valid, shuffle=True, batch_size=2, drop_last=True)\n",
    "max_epochs = 600\n",
    "validate_when = lambda e : ((e%2==0) and (e!=0)) or (e==max_epochs-1)\n",
    "model = Model(\n",
    "    lambda_reg = 90,\n",
    "    compute_sim_loss = mse_loss\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_curves_train = LossCurves(\"training\")\n",
    "loss_curves_valid = LossCurves(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e309a14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for e in range(max_epochs):\n",
    "    print(f'Epoch {e+1}/{max_epochs}:')\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    dl_train_iter = iter(dl_train)\n",
    "    while True:\n",
    "        try:\n",
    "            b1 = next(dl_train_iter)\n",
    "            b2 = next(dl_train_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(b1['fa'], b2['fa'])\n",
    "        model_output.all_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_curves_train.add_to_buffer(model_output)\n",
    "        del(model_output)\n",
    "    loss_curves_train.aggregate_buffers_for_epoch(e)\n",
    "    print(f\"\\tTraining loss: {loss_curves_train.all_losses[-1]:.4f} ({loss_curves_train.sim_losses[-1]:.4f},{loss_curves_train.gradicon_losses[-1]:.4f})\")\n",
    "    \n",
    "    # Validate\n",
    "    if validate_when(e):\n",
    "        model.eval()\n",
    "        dl_valid_iter = iter(dl_valid)\n",
    "        while True:\n",
    "            try:\n",
    "                b1 = next(dl_valid_iter)\n",
    "                b2 = next(dl_valid_iter)\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model_output = model(b1['fa'], b2['fa'])\n",
    "                loss_curves_valid.add_to_buffer(model_output)\n",
    "        loss_curves_valid.aggregate_buffers_for_epoch(e) \n",
    "        print(\"\\tValidation loss:\", loss_curves_valid.all_losses[-1])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "\n",
    "loss_curves_train.plot(savepath = footsteps.output_dir + 'loss_plot_train.png')\n",
    "loss_curves_valid.plot(savepath = footsteps.output_dir + 'loss_plot_valid.png')\n",
    "\n",
    "with open(footsteps.output_dir + 'loss_curves.p', 'wb') as f:\n",
    "    pickle.dump([loss_curves_train, loss_curves_valid],f)\n",
    "\n",
    "torch.save(model.state_dict(), footsteps.output_dir + 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "\n",
    "model.load_state_dict(torch.load(footsteps.output_dir + 'model_state_dict.pth'))\n",
    "\n",
    "with open(footsteps.output_dir + 'loss_curves.p', 'rb') as f:\n",
    "    loss_curves_train, loss_curves_valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42565b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "d1 = random.choice(ds_valid)\n",
    "d2 = random.choice(ds_valid)\n",
    "img_A = d1['fa'].unsqueeze(0)\n",
    "img_B = d2['fa'].unsqueeze(0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output = model(img_A,img_B)\n",
    "\n",
    "img_B_warped = warp(img_B, model_output.deformation_AB)\n",
    "\n",
    "preview_slices = (80,80,80)\n",
    "\n",
    "print(\"moving:\")\n",
    "util.preview_image(img_B[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"warped moving:\")\n",
    "util.preview_image(img_B_warped[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"target:\")\n",
    "util.preview_image(img_A[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"checkerboard of warped moving and target:\")\n",
    "util.preview_checkerboard(img_A[0,0].cpu(), img_B_warped[0,0].cpu(), figsize=(18,10), slices=preview_slices)\n",
    "print(\"deformation vector field:\")\n",
    "util.preview_3D_vector_field(model_output.deformation_AB[0].cpu(), slices=preview_slices)\n",
    "print(\"deformed grid:\")\n",
    "util.preview_3D_deformation(model_output.deformation_AB[0].cpu(),5, slices=preview_slices)\n",
    "print(\"jacobian determinant:\")\n",
    "det = util.jacobian_determinant(model_output.deformation_AB[0].cpu())\n",
    "util.preview_image(det, normalize_by='slice', threshold=0, slices=preview_slices)\n",
    "print(\"sim loss:\", model_output.sim_loss.item())\n",
    "print(\"gradicon loss:\", model_output.gradicon_loss.item())\n",
    "print(\"overall loss:\", model_output.all_loss.item())\n",
    "print(\"Number of folds:\", (det<0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0925d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
