{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94cda0",
   "metadata": {},
   "source": [
    "GradICON deformable registration of FA images. (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a72721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7490849",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_dir = 'dti_fit_images/fa'\n",
    "data = [{\"fa\":path, \"filename\":os.path.basename(path)} for path in glob.glob(os.path.join(fa_dir,'*'))]\n",
    "data_train, data_valid = monai.data.utils.partition_dataset(data, ratios=(8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59aeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImageD(keys=\"fa\"),\n",
    "    monai.transforms.AddChannelD(keys=\"fa\"),\n",
    "    # The input images are known (140,140,140); we pad out to 144 in each dim\n",
    "    monai.transforms.SpatialPadD(keys=\"fa\", spatial_size=(144,144,144), mode=\"constant\"),\n",
    "    monai.transforms.ToTensorD(keys=\"fa\"),\n",
    "    monai.transforms.ToDeviceD(keys=\"fa\", device=device),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38469b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train = monai.data.CacheDataset(data_train, transform)\n",
    "ds_valid = monai.data.CacheDataset(data_valid, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16992b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_net = monai.networks.nets.UNet(\n",
    "    3,  # spatial dims\n",
    "    2,  # input channels (one for fixed image and one for moving image)\n",
    "    3,  # output channels (to represent 3D displacement vector field)\n",
    "    (16, 32, 32, 32, 32, 64),  # channel sequence\n",
    "    (1, 2, 2, 2, 2),  # convolutional strides\n",
    "    dropout=0.2,\n",
    "    norm=\"batch\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc51bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = monai.networks.blocks.Warp(mode=\"bilinear\", padding_mode=\"zeros\")\n",
    "\n",
    "def sim_loss(b1, b2):\n",
    "    \"\"\"Return image similarity loss given two batches b1 and b2 of shape (batch_size, channels, H,W,D)\"\"\"\n",
    "    return ((b1-b2)**2).mean()\n",
    "\n",
    "def compose_ddf(u,v):\n",
    "    \"\"\"Compose two displacement fields, return the displacement that warps by v followed by u\"\"\"\n",
    "    return u + warp(v,u)\n",
    "\n",
    "_, H, W, D = ds_train[0]['fa'].shape\n",
    "\n",
    "# Compute discrete spatial derivatives\n",
    "def diff_and_trim(array, axis):\n",
    "    \"\"\"Take the discrete difference along a spatial axis, which should be 2,3, or 4.\n",
    "    Return a difference tensor with all spatial axes trimmed by 1.\"\"\"\n",
    "    return torch.diff(array, axis=axis)[:, :, :(H-1), :(W-1), :(D-1)]\n",
    "\n",
    "def size_of_spatial_derivative(u):\n",
    "    \"\"\"Return the squared Frobenius norm of the spatial derivative of the given displacement field.\n",
    "    To clarify, this is about the derivative of the actual displacement field map, not the deformation\n",
    "    that the displacement field map defines. The expected input shape is (batch,3,H,W,D).\n",
    "    Output shape is (batch).\"\"\"\n",
    "    dx = diff_and_trim(u, 2)\n",
    "    dy = diff_and_trim(u, 3)\n",
    "    dz = diff_and_trim(u, 4)\n",
    "    return(dx**2 + dy**2 + dz**2).sum(axis=1).mean(axis=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d09c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = monai.data.DataLoader(ds_train, shuffle=True, batch_size=2, drop_last=True)\n",
    "max_epochs = 1\n",
    "for e in range(max_epochs):\n",
    "    dl_train_iter = iter(dl_train)\n",
    "    while True:\n",
    "        try:\n",
    "            b1 = next(dl_train_iter)\n",
    "            b2 = next(dl_train_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        print('peup')\n",
    "        \n",
    "        img_A = b1['fa']\n",
    "        img_B = b2['fa']\n",
    "        img_pair_AB = torch.cat((img_A, img_B), dim=1)\n",
    "        img_pair_BA = img_pair_AB[:,[1,0]]\n",
    "        \n",
    "        deformation_AB = reg_net(img_pair_AB) # deforms img_B to the space of img_A\n",
    "        deformation_BA = reg_net(img_pair_BA) # deforms img_A to the space of img_B\n",
    "        \n",
    "        img_B_warped = warp(img_B, deformation_AB)\n",
    "        img_A_warped = warp(img_A, deformation_BA)\n",
    "        sim_loss_A = sim_loss(img_A, img_B_warped)\n",
    "        sim_loss_B = sim_loss(img_B, img_A_warped)\n",
    "        composite_deformation_B = compose_ddf(deformation_BA, deformation_AB)\n",
    "        composite_deformation_A = compose_ddf(deformation_AB, deformation_BA)\n",
    "        gradicon_loss_A = size_of_spatial_derivative(composite_deformation_A).mean()\n",
    "        gradicon_loss_B = size_of_spatial_derivative(composite_deformation_B).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
