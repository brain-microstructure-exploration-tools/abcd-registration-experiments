{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6823d475",
   "metadata": {},
   "source": [
    "In this notebook we devise and test out a technique for compuing the discrete spatial derivative matrix of a 3D transformation that is represented by a direct displacement vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from util import plot_2D_deformation, plot_2D_vector_field, preview_3D_deformation, preview_3D_vector_field, preview_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from https://github.com/ebrahimebrahim/deep-atlas/blob/main/warp_action_exploration.ipynb\n",
    "\n",
    "def get_example_ddf_2D(s_x, s_y=None, variant=0):\n",
    "    \"\"\"Get an example DDF (direct displacement field).\n",
    "    Arguments:\n",
    "        s_x, s_y: The x and y scale. Provide s_x only to have them be the same scale.\n",
    "            \"Scale\" here really means \"resolution.\" Think of it as the same underlying displacement,\n",
    "            but meant to be applied to images at different resolutions.\n",
    "        variant: integer selector for which variant of example to return.\n",
    "    \"\"\"\n",
    "    if s_y is None:\n",
    "        s_y=s_x\n",
    "    if variant==0:\n",
    "        ddf = torch.tensor(\n",
    "            [[\n",
    "                [(s_y/32)*math.sin(2*math.pi*(y/s_y) * 3),(s_x/32)*2*math.cos(2*math.pi* (x/s_x) * 2)]\n",
    "                for x in range(s_x)]\n",
    "                for y in range(s_y)\n",
    "            ]\n",
    "        ).permute((2,0,1))\n",
    "    elif variant==1:\n",
    "        ddf = torch.tensor(\n",
    "            [[\n",
    "                [(s_y/32)*math.sin(2*math.pi*(x/s_x) * 3),(s_x/32)*2*math.cos(2*math.pi* (y/s_y) * 2)]\n",
    "                for x in range(s_x)]\n",
    "                for y in range(s_y)\n",
    "            ]\n",
    "        ).permute((2,0,1))\n",
    "    else:\n",
    "        raise ValueError(f\"There is no variant {variant}\")\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659cc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some 3D examples to test things out on\n",
    "\n",
    "def get_example_ddf_3d(s_x, s_y=None, s_z=None, variant=0):\n",
    "    \"\"\"Get an example DDF (direct displacement field).\n",
    "    Arguments:\n",
    "        s_x, s_y. s_z: The x,y,z scales. Provide s_x only to have them be the same scale.\n",
    "            \"Scale\" here really means \"resolution.\" Think of it as the same underlying displacement,\n",
    "            but meant to be applied to images at different resolutions.\n",
    "        variant: integer selector for which variant of example to return.\n",
    "    \"\"\"\n",
    "    if s_y is None:\n",
    "        s_y=s_x\n",
    "    if s_z is None:\n",
    "        s_z = s_x\n",
    "    if variant==0:\n",
    "        ddf = torch.tensor(\n",
    "            [[[\n",
    "                [\n",
    "                    (s_z/32)*math.sin(2*math.pi*(y/s_y + x/s_x) * 2.5),\n",
    "                    (s_y/32)*math.sin(2*math.pi*(y/s_y) * 3),\n",
    "                    (s_x/32)*2*math.cos(2*math.pi* (x/s_x) * 2),\n",
    "                ]\n",
    "                for x in range(s_x)]\n",
    "                for y in range(s_y)]\n",
    "                for z in range(s_z)\n",
    "            ]\n",
    "        ).permute((3,0,1,2))\n",
    "    elif variant==1:\n",
    "        ddf = torch.tensor(\n",
    "            [[[\n",
    "                [\n",
    "                    (s_z/32)*math.sin(2*math.pi*(y/s_y + x/s_x) * 2.5),\n",
    "                    (s_y/32)*math.sin(2*math.pi*(x/s_x) * 3),\n",
    "                    (s_x/32)*2*math.cos(2*math.pi* (y/s_y) * 2),\n",
    "                ]\n",
    "                for x in range(s_x)]\n",
    "                for y in range(s_y)]\n",
    "                for z in range(s_z)\n",
    "            ]\n",
    "        ).permute((3,0,1,2))\n",
    "    elif variant==2:\n",
    "        ddf = torch.tensor(\n",
    "            [[[\n",
    "                [\n",
    "                    (s_z/32)*( 1*z/s_z + 2*y/s_y + 3*x/s_x ),\n",
    "                    (s_y/32)*( 4*z/s_z + 5*y/s_y + 6*x/s_x ),\n",
    "                    (s_x/32)*( 7*z/s_z + 8*y/s_y + 9*x/s_x ),\n",
    "                ]\n",
    "                for x in range(s_x)]\n",
    "                for y in range(s_y)]\n",
    "                for z in range(s_z)\n",
    "            ]\n",
    "        ).permute((3,0,1,2))\n",
    "    else:\n",
    "        raise ValueError(f\"There is no variant {variant}\")\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1113642",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = get_example_ddf_3d(60,variant=2)\n",
    "preview_3D_vector_field(ddf, downsampling=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef56bc",
   "metadata": {},
   "source": [
    "Plan:\n",
    "- Copy the MedianBlur filter design I made earlier; we will similarly make a 3D conv layer with a fixed kernel\n",
    "- Define the kernel. It will take us from 3 channels to 9 channels. For each of the 3 input channels i in (x,y,z), there are 3 tensors (indexed by j in (x,y,z)) of shape 3x3x3 that help us compute central differences. The i,j tensor is a 3x3x3 tensor that helps us compute the derivative of the i^th component with respect to the j^th variable.\n",
    "  - Done below; the best appraoch tuend out to be to move channel dimension into batch dimension, compute gradient, and then return channel dimension back to where it was.\n",
    "- Check out MONAI approach to sobel kernel?\n",
    "  - It does not seem to be intended for what we need (it's a transform and not a network layer).\n",
    "- Remember to multiply by 1/2 for central difference. Remember to pad reasonably.\n",
    "  - We replicate-pad after computing the derivative. It's good enough; see the docstring below.\n",
    "- The convolution with this kernel helps us take a derivative of a function, not a DDF. Correct this by adding the appropriate fixed map.\n",
    "  - It is now designed to work with a DDF, by adding a bias after convolution.\n",
    "- Next we must address the problem of applying the inverse of the jacobian to the diffusion tensors, \"contracting\" it with both indices of the diffusion tensors. Frame this as a problem that can be solved by torch.linalg.solve, changing the view of the tensor fields such that the spatial dimensions and the columns/rows are merged into the batch dimension.\n",
    "  - Going back to work n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b46ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_kernel_bias() -> torch.Tensor:\n",
    "    \"\"\"Create sobel style kernel and bias for computing spatial derivatives (via central difference).\n",
    "    This is specifically for use with the spatial_derivative function defined below.\"\"\"\n",
    "    kernel: torch.Tensor = torch.zeros(3,1,3,3,3)\n",
    "    \n",
    "    # sobel x\n",
    "    kernel[0,0,0,1,1] -= 0.5\n",
    "    kernel[0,0,2,1,1] += 0.5\n",
    "    \n",
    "    # sobel y\n",
    "    kernel[1,0,1,0,1] -= 0.5\n",
    "    kernel[1,0,1,2,1] += 0.5\n",
    "    \n",
    "    # sobel z\n",
    "    kernel[2,0,1,1,0] -= 0.5\n",
    "    kernel[2,0,1,1,2] += 0.5\n",
    "    \n",
    "    # The kernel constructed above can be used to get the spatial gradient of a scalar function, shape (b,1,H,W,D)\n",
    "    \n",
    "    # The bias is what we need to add to each channel in order to go from looking at the derivative of the\n",
    "    # displacement field to looking at the derivative of the transformation\n",
    "    bias = torch.eye(3,3, dtype=kernel.dtype).reshape(-1)\n",
    "    \n",
    "    return kernel, bias\n",
    "\n",
    "def spatial_derivative(input: torch.Tensor, kernel_bias: Tuple[torch.Tensor, torch.Tensor] = None) -> torch.Tensor:\n",
    "    r\"\"\"Compute the spatial derivative of a 3D transformation represented as a displacement vector field.\n",
    "\n",
    "    Args:\n",
    "        input: the input image representing a spatial transformation as a displacement vector field;\n",
    "            should have shape :math:`(B,3,H,W,D)`\n",
    "        kernel: optionally a prebuilt kernel and bias to use\n",
    "             kernel shape: :math:`(9,1,3,3,3)`\n",
    "             bias shape:   :math:`(9,)`\n",
    "\n",
    "    Returns:\n",
    "        the jacobian matrix field with shape :math:`(B,9,H,W,D)`,\n",
    "        where the entry (b,c,x,y,z) has the following interpretation for image at batch index b\n",
    "        located at (x,y,z) at each value of i:\n",
    "            i=0: x-derivative of of the x-component of the transformation\n",
    "            i=1: y-derivative of of the x-component of the transformation\n",
    "            i=2: z-derivative of of the x-component of the transformation\n",
    "            i=3: x-derivative of of the y-component of the transformation\n",
    "            i=4: y-derivative of of the y-component of the transformation\n",
    "            i=5: z-derivative of of the y-component of the transformation\n",
    "            i=6: x-derivative of of the z-component of the transformation\n",
    "            i=7: y-derivative of of the z-component of the transformation\n",
    "            i=8: z-derivative of of the z-component of the transformation\n",
    "    \n",
    "    If you reshape the return value to (B,3,3,H,W,D) then you will have 3x3 jacobian matrices\n",
    "    living in the dimensions 1 and 2. That is, [b,:,:,x,y,z] will be the 3x3 jacobian matrix\n",
    "    for the transformation with batch index b at location (x,y,z).\n",
    "    \"\"\"\n",
    "    if not isinstance(input, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(input)}\")\n",
    "\n",
    "    if not len(input.shape) == 5 or input.shape[1]!=3:\n",
    "        raise ValueError(f\"Invalid input shape, we expect Bx3xHxWxD. Got: {input.shape}\")\n",
    "\n",
    "\n",
    "    if kernel_bias is None:\n",
    "        kernel, bias = get_kernel().to(input)\n",
    "    else:\n",
    "        kernel, bias = kernel_bias\n",
    "    \n",
    "    b,c,h,w,d = input.shape\n",
    "    assert(c==3)\n",
    "    deriv: torch.Tensor = F.conv3d(input.view(b*c,1,h,w,d), kernel, stride=1, groups=1)\n",
    "    deriv = F.pad(deriv, (1,1,1,1,1,1), mode='replicate')\n",
    "    deriv = deriv.view(b,3*c,h,w,d)\n",
    "    deriv += bias.view(1,9,1,1,1)\n",
    "    \n",
    "\n",
    "    return deriv\n",
    "\n",
    "\n",
    "\n",
    "class DerivativeOfDDF(nn.Module):\n",
    "    r\"\"\"Compute the spatial derivative of a 3D transformation represented as a displacement vector field.\n",
    "    \n",
    "    We use central difference. In order to keep spatial dimensions the same,\n",
    "    the boundary is padded in \"replicate\" mode, so the derivatives on the boundary\n",
    "    are off by one voxel. That is, the derivatives are firt computed to produce a smaller image,\n",
    "    and then replication padding fixes the image size.\n",
    "    This is not ideal (a better approach would be to use forward-difference\n",
    "    or backward difference at the boundaries), but this is much simpler, and it shouldn't\n",
    "    matter very much (it matters only when the displacement field has large second derivatives\n",
    "    at the boundary *and* when what happens at the boundary is actually important-- this situation\n",
    "    is just not very likely for my use case.)\n",
    "\n",
    "    Args:\n",
    "        input: the input image representing a spatial trans\n",
    "\n",
    "    Returns:\n",
    "        the jacobian matrix field with shape :math:`(B,9,H,W,D)`,\n",
    "        where the entry (b,c,x,y,z) has the following interpretation for image at batch index b\n",
    "        located at (x,y,z) at each value of i:\n",
    "            i=0: x-derivative of of the x-component of the transformation\n",
    "            i=1: y-derivative of of the x-component of the transformation\n",
    "            i=2: z-derivative of of the x-component of the transformation\n",
    "            i=3: x-derivative of of the y-component of the transformation\n",
    "            i=4: y-derivative of of the y-component of the transformation\n",
    "            i=5: z-derivative of of the y-component of the transformation\n",
    "            i=6: x-derivative of of the z-component of the transformation\n",
    "            i=7: y-derivative of of the z-component of the transformation\n",
    "            i=8: z-derivative of of the z-component of the transformation\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(B, 3, H, W, D)`\n",
    "        - Output: :math:`(B, 9, H, W, D)`\n",
    "    \n",
    "    If you reshape the ouput to (B,3,3,H,W,D) then you will have 3x3 jacobian matrices\n",
    "    living in the dimensions 1 and 2. That is, [b,:,:,x,y,z] will be the 3x3 jacobian matrix\n",
    "    for the transformation with batch index b at location (x,y,z).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device='cpu') -> None:\n",
    "        super().__init__()\n",
    "        self.kernel, self.bias = get_kernel_bias()\n",
    "        self.kernel = self.kernel.to(device);\n",
    "        self.bias = self.bias.to(device);\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return spatial_derivative(input, (self.kernel, self.bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d69b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'cuda'\n",
    "deriv_ddf = DerivativeOfDDF(device=dev)\n",
    "ddf0 = get_example_ddf_3d(60,variant=0).to(dev)\n",
    "ddf1 = get_example_ddf_3d(60,variant=1).to(dev)\n",
    "ddf2 = get_example_ddf_3d(60,variant=2).to(dev)\n",
    "ddfs = torch.stack([ddf0, ddf1, ddf2])\n",
    "d = deriv_ddf(ddfs)\n",
    "d_mat = d.view((3,3,3,60,60,60))\n",
    "d_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out at a bunch of voxels\n",
    "\n",
    "B,C,H,W,D = ddfs.shape\n",
    "assert(C==3)\n",
    "for _ in range(10000):\n",
    "    b=np.random.randint(B)\n",
    "    x=np.random.randint(1,H-1) # It does not work exactly on the boundary-- see docstring\n",
    "    y=np.random.randint(1,W-1)\n",
    "    z=np.random.randint(1,D-1)\n",
    "    i,j = np.random.randint(3,size=(2,))\n",
    "    deriv = d_mat[b,i,j,x,y,z]\n",
    "    if j==0:\n",
    "        true_deriv = (ddfs[b,i,x+1,y,z] - ddfs[b,i,x-1,y,z])/2\n",
    "    elif j==1:\n",
    "        true_deriv = (ddfs[b,i,x,y+1,z] - ddfs[b,i,x,y-1,z])/2\n",
    "    else:\n",
    "        true_deriv = (ddfs[b,i,x,y,z+1] - ddfs[b,i,x,y,z-1])/2\n",
    "    if i==j:\n",
    "        true_deriv += 1\n",
    "    error = (true_deriv - deriv).abs()\n",
    "    if not error<1e-5: # There is some numerical error\n",
    "        print(error, true_deriv, deriv, 'params:', b,i,j,x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7325f8b",
   "metadata": {},
   "source": [
    "Seems to work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
