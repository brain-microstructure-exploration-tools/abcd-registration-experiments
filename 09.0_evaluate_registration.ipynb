{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9bf8f0",
   "metadata": {},
   "source": [
    "This notebook evaluates a bunch of registration models based on their ability to align diffusion tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa95543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from spatial_derivatives import JacobianOfDDF\n",
    "from dti_warp import WarpDTI, TensorTransformType, PolarDecompositionMode, MseLossDTI, aoe_dti\n",
    "import util\n",
    "import shutil\n",
    "import time\n",
    "import ants\n",
    "import importlib.util\n",
    "import sys\n",
    "from collections import defaultdict, namedtuple\n",
    "from customRandAffine import AffineAugmentationDTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ececd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "spatial_size = (144,144,144)\n",
    "\n",
    "data_dir = Path('./dti_fit_images_test/')\n",
    "fa_dir = data_dir/'fa'\n",
    "dti_dir = data_dir/'dti'\n",
    "data = [{'dti':str(path), 'fa':str(path.parent.parent/'fa'/path.name), \"filename\":path.name} for path in dti_dir.glob('*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ['fa', 'dti']\n",
    "\n",
    "transform = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImageD(keys=k),\n",
    "    monai.transforms.EnsureChannelFirstD(keys=k),\n",
    "    monai.transforms.SpatialPadD(keys=k, spatial_size=spatial_size, mode=\"constant\"),\n",
    "    monai.transforms.ToTensorD(keys=k),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da32744",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "jac = JacobianOfDDF('cpu')\n",
    "\n",
    "warp_dti = WarpDTI(\n",
    "    device='cpu',\n",
    "    tensor_transform_type=TensorTransformType.FINITE_STRAIN,\n",
    "    polar_decomposition_mode=PolarDecompositionMode.HALLEY_DYNAMIC_WEIGHTS,\n",
    "    num_iterations = 9\n",
    ")\n",
    "\n",
    "warp_scalar = monai.networks.blocks.Warp(mode='nearest')\n",
    "\n",
    "mse_dti = MseLossDTI('cpu')\n",
    "\n",
    "affine_aug = AffineAugmentationDTI(spatial_size, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caching = \"disk\"\n",
    "\n",
    "if caching == \"disk\":\n",
    "    cache_dir = Path('./PersistentDatasetCacheDir')\n",
    "    if cache_dir.exists():\n",
    "        shutil.rmtree(cache_dir)\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    ds = monai.data.PersistentDataset(data, transform, cache_dir=cache_dir/'train')\n",
    "\n",
    "elif caching == \"memory\":\n",
    "    ds = monai.data.CacheDataset(data, transform)\n",
    "\n",
    "dl = monai.data.DataLoader(ds, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0eb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_module_from_path(module_path, module_name):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    globals()[module_name] = module\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    \n",
    "import_module_from_path(\"models_to_benchmark/2022-09-13-deformable-2be0f3bd.py\", 'module_2be0f3bd')\n",
    "import_module_from_path(\"models_to_benchmark/dti-2022-10-23a-e11e483.py\", 'module_e11e483')\n",
    "import_module_from_path(\"models_to_benchmark/dti-2022-10-24a-10da6f4.py\", 'module_10da6f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop_model(fa1, fa2, dti1, dti2):\n",
    "    b,_,h,w,d = fa1.shape\n",
    "    ddf = torch.zeros(b,3,h,w,d,dtype=dti1.dtype)\n",
    "    fa2_warped = fa2\n",
    "    t = 0\n",
    "    return ddf, fa2_warped, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nii_path = lambda ants_transforms : [p for p in ants_transforms if '.nii' in Path(p).suffixes][0]\n",
    "def ants_model(fa1, fa2, dti1, dti2):\n",
    "    fa1_ants = ants.from_numpy(fa1.cpu().numpy()[0,0])\n",
    "    fa2_ants = ants.from_numpy(fa2.cpu().numpy()[0,0])\n",
    "    start_time = time.time()\n",
    "    ants_reg = ants.registration(fa1_ants, fa2_ants, type_of_transform='SyN')\n",
    "    t = time.time() - start_time\n",
    "    fa2_warped = torch.tensor(ants_reg['warpedmovout'].numpy()).unsqueeze(0).unsqueeze(0)\n",
    "    fwdtransform_path = get_nii_path(ants_reg['fwdtransforms'])\n",
    "    ddf = monai.transforms.LoadImage(image_only=True)(fwdtransform_path).permute((3,4,0,1,2))\n",
    "    return ddf, fa2_warped, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2be0f3bd = module_2be0f3bd.create_model(device)\n",
    "def model_2be0f3bd(fa1, fa2, dti1, dti2):\n",
    "    fa1_d, fa2_d = fa1.to(device), fa2.to(device)\n",
    "    start_time = time.time()\n",
    "    ddf,fa2_warped = net_2be0f3bd.forward_inference(fa1_d, fa2_d)\n",
    "    t = time.time() - start_time\n",
    "    return ddf.cpu(), fa2_warped.cpu(), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaa2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_e11e483 = module_e11e483.create_model(device)\n",
    "def model_e11e483(fa1, fa2, dti1, dti2):\n",
    "    dti1_d, dti2_d = dti1.to(device), dti2.to(device)\n",
    "    fa2_d = fa2.to(device)\n",
    "    start_time = time.time()\n",
    "    ddf = net_e11e483(dti1_d, dti2_d, return_warp_only=True)\n",
    "    fa2_warped = warp_scalar(fa2_d, ddf)\n",
    "    t = time.time() - start_time\n",
    "    return ddf.cpu(), fa2_warped.cpu(), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24518f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_10da6f4 = module_10da6f4.create_model(device)\n",
    "def model_10da6f4(fa1, fa2, dti1, dti2):\n",
    "    dti1_d, dti2_d = dti1.to(device), dti2.to(device)\n",
    "    fa2_d = fa2.to(device)\n",
    "    start_time = time.time()\n",
    "    ddf = net_10da6f4(dti1_d, dti2_d, return_warp_only=True)\n",
    "    fa2_warped = warp_scalar(fa2_d, ddf)\n",
    "    t = time.time() - start_time\n",
    "    return ddf.cpu(), fa2_warped.cpu(), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = namedtuple(\"Metrics\", \"fa_mse, fa_ncc, dti_mse, aoe, folds, t\")\n",
    "\n",
    "def compute_metrics(dti1, dti2, fa1, fa2, model):\n",
    "    \n",
    "    ddf, fa2_warped, t = model(fa1, fa2, dti1, dti2)\n",
    "    \n",
    "    fa_mse = ((fa2_warped - fa1)**2).mean().item()\n",
    "    fa_ncc = -util.ncc_loss(fa1,fa2_warped).item()\n",
    "    folds = (jac(ddf)<0).sum().item()\n",
    "\n",
    "    dti2_warped = warp_dti(dti2, ddf)\n",
    "\n",
    "    dti_mse = mse_dti(dti1, dti2_warped).item()\n",
    "    aoe = aoe_dti(dti1, dti2_warped, fa1).item()\n",
    "    \n",
    "    return Metrics(fa_mse, fa_ncc, dti_mse, aoe, folds, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62136ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Models to evaluate\n",
    "models = {\n",
    "    \"no-op\": noop_model,\n",
    "    \"ants\": ants_model,\n",
    "    \"fa-driven\": model_2be0f3bd,\n",
    "    \"dti-driven-no-affaug\": model_e11e483,\n",
    "    \"dti-driven-affaug\": model_10da6f4,\n",
    "}\n",
    "\n",
    "# Number of passes to make over the test data\n",
    "num_passes = 1\n",
    "\n",
    "model_metrics = { k: defaultdict(list) for k in models.keys() }\n",
    "\n",
    "for i in range(num_passes):\n",
    "    print(f\"pass {i+1}/{num_passes}\")\n",
    "    \n",
    "    dl_iter = iter(dl)\n",
    "    j=0\n",
    "    while True:\n",
    "        j+=1\n",
    "        print(f\"\\timg pair {j}/{len(ds)//2}\")\n",
    "        \n",
    "        try:\n",
    "            d1 = next(dl_iter)\n",
    "            d2 = next(dl_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "        dti1 = d1['dti']\n",
    "        dti2 = d2['dti']\n",
    "        fa1 = d1['fa']\n",
    "        fa2 = d2['fa']\n",
    "        \n",
    "        fa1, fa2, dti1, dti2 = affine_aug(fa1, fa2, dti1, dti2)\n",
    "        \n",
    "        print('\\t\\t',end='')\n",
    "        for model_key, model in models.items():\n",
    "            print(model_key,'...',end='')\n",
    "            metrics = compute_metrics(dti1, dti2, fa1, fa2, model)\n",
    "            for metric_name, metric_value in metrics._asdict().items():\n",
    "                model_metrics[model_key][metric_name].append(metric_value)\n",
    "        print()\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_means = defaultdict(list)\n",
    "df_dict_medians = defaultdict(list)\n",
    "metric_names = list(Metrics._fields)\n",
    "for model_key,metrics in model_metrics.items():\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric_list = metrics[metric_name]\n",
    "        mean_metric = np.mean(metric_list)\n",
    "        median_metric = np.median(metric_list)\n",
    "                \n",
    "        df_dict_means[model_key].append(mean_metric)\n",
    "        df_dict_medians[model_key].append(median_metric)\n",
    "\n",
    "df_means = pd.DataFrame.from_dict(df_dict_means, orient='index', columns=metric_names)\n",
    "df_medians = pd.DataFrame.from_dict(df_dict_medians, orient='index', columns=metric_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c60d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Means of metrics:\")\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Medians of metrics:\")\n",
    "df_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.to_csv('evaluation_tables/evaluation_means.csv')\n",
    "df_medians.to_csv('evaluation_tables/evaluation_medians.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
