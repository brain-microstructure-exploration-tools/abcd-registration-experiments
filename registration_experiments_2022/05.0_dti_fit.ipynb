{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94cda0",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate on a randomly selected diffusion weighted dataset how we can obtain a DTI fit, save it to a file, and save an FA image from it. The accompanying script `05.1_dti_fit.py` actually does this stuff to the full dataset. This notebook is just a demo to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a72721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dipy.io.image\n",
    "import dipy.io\n",
    "import dipy.core.gradients\n",
    "import dipy.reconst.dti\n",
    "import dipy.segment.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7490849",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ebrahim/data/abcd/DMRI_extracted'\n",
    "img_dirs = glob.glob(os.path.join(data_dir,'*ABCD-MPROC-DTI*/sub-*/ses-*/dwi/'))\n",
    "output_dir = './dti_fit_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4467f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_fmriresults01_df = pd.read_csv('01.0_abcd_sample/sampled_fmriresults01.csv')\n",
    "sampled_fmriresults01_df['dirname'] = sampled_fmriresults01_df.derived_files.apply(lambda x : x.split('/')[-1].strip('.tgz'))\n",
    "dirname_to_full_path = {img_dir.split('/')[-5]:img_dir for img_dir in img_dirs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5a42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for (subjectkey,interview_age),df in sampled_fmriresults01_df.groupby(['subjectkey', 'interview_age']):\n",
    "    paths = []\n",
    "    for _,row in df.iterrows():\n",
    "        if row.dirname not in dirname_to_full_path.keys():\n",
    "            raise FileNotFoundError(f\"Could not find a directory for fmriresults01 id {row.fmriresults01_id}\")\n",
    "        img_dir = dirname_to_full_path[row.dirname]\n",
    "        dwi_path = glob.glob(os.path.join(img_dir, '*.nii'))[0]\n",
    "        bval_path = glob.glob(os.path.join(img_dir, '*.bval'))[0]\n",
    "        bvec_path = glob.glob(os.path.join(img_dir, '*.bvec'))[0]\n",
    "        paths.append({\n",
    "            'img_dir' : img_dir,\n",
    "            'dwi_path' : dwi_path,\n",
    "            'bval_path' : bval_path,\n",
    "            'bvec_path' : bvec_path,\n",
    "        })\n",
    "    data.append({\n",
    "        'paths' : paths,\n",
    "\n",
    "        'subjectkey' : row.subjectkey,\n",
    "        'interview_age' : row.interview_age,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269f6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 \t NDAR_INV1306ZGW1 \t 115 \n",
      "103 \t NDAR_INV36E4JVZ2 \t 129 \n",
      "103 \t NDAR_INV36E4JVZ2 \t 153 \n",
      "104 \t NDAR_INV3XNH8EYM \t 138 \n",
      "103 \t NDAR_INV4C8YJ9BG \t 131 \n",
      "103 \t NDAR_INV4C8YJ9BG \t 157 \n",
      "103 \t NDAR_INV52XG9LJ3 \t 114 \n",
      "103 \t NDAR_INV52XG9LJ3 \t 138 \n",
      "103 \t NDAR_INV5K67LYGB \t 127 \n",
      "103 \t NDAR_INV5K67LYGB \t 151 \n",
      "103 \t NDAR_INV5U9JTZ3X \t 113 \n",
      "51 \t NDAR_INV6L7B1GX3 \t 133 (part 1 of 2)\n",
      "51 \t NDAR_INV6L7B1GX3 \t 133 (part 2 of 2)\n",
      "104 \t NDAR_INV72Z70LY1 \t 136 \n",
      "103 \t NDAR_INV7H3FYUBB \t 121 \n",
      "103 \t NDAR_INV7H3FYUBB \t 146 \n",
      "103 \t NDAR_INV7L2M29CY \t 114 \n",
      "103 \t NDAR_INV7NVJNHRE \t 112 \n",
      "104 \t NDAR_INV7NVJNHRE \t 136 \n",
      "104 \t NDAR_INV7RGX9G26 \t 109 \n",
      "103 \t NDAR_INV93DMBG2D \t 111 \n",
      "103 \t NDAR_INV9D6W29Z7 \t 123 \n",
      "104 \t NDAR_INV9D6W29Z7 \t 146 \n",
      "103 \t NDAR_INV9KX83G7Z \t 111 \n",
      "103 \t NDAR_INV9KX83G7Z \t 135 \n",
      "103 \t NDAR_INVB2FVBDTD \t 120 \n",
      "103 \t NDAR_INVB2FVBDTD \t 144 \n",
      "103 \t NDAR_INVB349E4D3 \t 128 \n",
      "103 \t NDAR_INVB349E4D3 \t 152 \n",
      "103 \t NDAR_INVBB9X243N \t 117 \n",
      "103 \t NDAR_INVC624EF1K \t 109 \n",
      "103 \t NDAR_INVC624EF1K \t 131 \n",
      "103 \t NDAR_INVCX9VNMT6 \t 113 \n",
      "103 \t NDAR_INVCX9VNMT6 \t 140 \n",
      "103 \t NDAR_INVDLR8T512 \t 127 \n",
      "103 \t NDAR_INVDLR8T512 \t 148 \n",
      "103 \t NDAR_INVE56GMC5F \t 120 \n",
      "103 \t NDAR_INVEDF5950W \t 121 \n",
      "103 \t NDAR_INVEDF5950W \t 144 \n",
      "103 \t NDAR_INVFVXF1HTH \t 113 \n",
      "103 \t NDAR_INVFY31ZKY7 \t 152 \n",
      "103 \t NDAR_INVFZ7B9KJ8 \t 108 \n",
      "103 \t NDAR_INVFZ7B9KJ8 \t 133 \n",
      "103 \t NDAR_INVG0E0L3HV \t 131 \n",
      "103 \t NDAR_INVG0E0L3HV \t 156 \n",
      "51 \t NDAR_INVGXCZ2ELG \t 120 (part 1 of 2)\n",
      "51 \t NDAR_INVGXCZ2ELG \t 120 (part 2 of 2)\n",
      "51 \t NDAR_INVGXCZ2ELG \t 145 (part 1 of 2)\n",
      "51 \t NDAR_INVGXCZ2ELG \t 145 (part 2 of 2)\n",
      "103 \t NDAR_INVJ7L6EW0J \t 129 \n",
      "103 \t NDAR_INVJHYBD2XK \t 125 \n",
      "103 \t NDAR_INVJHYBD2XK \t 149 \n",
      "103 \t NDAR_INVK86BCPMG \t 117 \n",
      "104 \t NDAR_INVK86BCPMG \t 141 \n",
      "103 \t NDAR_INVKFUY5YHC \t 120 \n",
      "104 \t NDAR_INVKFUY5YHC \t 146 \n",
      "51 \t NDAR_INVL124KUNM \t 146 (part 1 of 2)\n",
      "51 \t NDAR_INVL124KUNM \t 146 (part 2 of 2)\n",
      "103 \t NDAR_INVLN9JCZ56 \t 131 \n",
      "103 \t NDAR_INVLN9JCZ56 \t 158 \n",
      "103 \t NDAR_INVM9VTUE2G \t 117 \n",
      "103 \t NDAR_INVMJTPRDKA \t 131 \n",
      "103 \t NDAR_INVN9D4XZKE \t 119 \n",
      "103 \t NDAR_INVN9D4XZKE \t 143 \n",
      "103 \t NDAR_INVNVZEHYV5 \t 124 \n",
      "103 \t NDAR_INVPDW73ZHF \t 125 \n",
      "104 \t NDAR_INVPDW73ZHF \t 146 \n",
      "103 \t NDAR_INVPRNEYMH1 \t 108 \n",
      "103 \t NDAR_INVR62PJ1EJ \t 111 \n",
      "103 \t NDAR_INVRXN9H1J6 \t 140 \n",
      "103 \t NDAR_INVTANY2ML3 \t 113 \n",
      "103 \t NDAR_INVU7VVFRJX \t 130 \n",
      "51 \t NDAR_INVU9VKB2N8 \t 142 (part 1 of 2)\n",
      "51 \t NDAR_INVU9VKB2N8 \t 142 (part 2 of 2)\n",
      "103 \t NDAR_INVUAYNYWT7 \t 110 \n",
      "104 \t NDAR_INVUAYNYWT7 \t 135 \n",
      "103 \t NDAR_INVULJ63ZZK \t 121 \n",
      "51 \t NDAR_INVVM0UX0L1 \t 110 (part 1 of 2)\n",
      "51 \t NDAR_INVVM0UX0L1 \t 110 (part 2 of 2)\n",
      "51 \t NDAR_INVVM0UX0L1 \t 134 (part 1 of 2)\n",
      "51 \t NDAR_INVVM0UX0L1 \t 134 (part 2 of 2)\n",
      "103 \t NDAR_INVX3ZLE0DN \t 110 \n",
      "103 \t NDAR_INVX5326K7A \t 109 \n",
      "104 \t NDAR_INVX6BE06VZ \t 109 \n",
      "104 \t NDAR_INVX6BE06VZ \t 139 \n",
      "103 \t NDAR_INVXHXZ933C \t 130 \n",
      "103 \t NDAR_INVXZRDA6CJ \t 130 \n",
      "103 \t NDAR_INVXZRDA6CJ \t 152 \n",
      "103 \t NDAR_INVY6XXVZT3 \t 130 \n",
      "103 \t NDAR_INVZGDMXH98 \t 114 \n",
      "104 \t NDAR_INVZGDMXH98 \t 139 \n",
      "103 \t NDAR_INVZJDPXX7G \t 118 \n"
     ]
    }
   ],
   "source": [
    "# Run this to look at the number of bvals for each image, alongside subject id and interview age\n",
    "\n",
    "for d in data:\n",
    "    for i,p in enumerate(d['paths']):\n",
    "        bvals, bvecs = dipy.io.read_bvals_bvecs(p['bval_path'], p['bvec_path'])\n",
    "        print(f\"{len(bvals)} \\t {d['subjectkey']} \\t {d['interview_age']}\",\n",
    "              f\"(part {i+1} of {len(d['paths'])})\" if len(d['paths'])>1 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760a2e8",
   "metadata": {},
   "source": [
    "Notice a few things here:\n",
    "- There are scan sessions that got split up over multiple files, ~~maybe because there was a break in the middle of scanning~~ Actually it's because the Philips scanners always produce two image files, this is pointed out in the ABCD release notes (look for \"ABCD Imaging Instruments\", \"Expected File Sets\"). For those there are 51+51 = 102 total b-values, with one b=3000 image being missing compared to what is described in the [scanning protocol](https://abcdstudy.org/images/Protocol_Imaging_Sequences.pdf).\n",
    "- Even among the non-split files, the total number of b-values varies among 103,104. When there are 104 b-values it seems that there's an extra b=0 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7edd5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from one of the dictionaries listed in the object \"data\" defined above\n",
    "def load_data(d):\n",
    "    img_data_list =[]\n",
    "    bvals_list = []\n",
    "    bvecs_list = []\n",
    "    prev_affine_transform = None\n",
    "\n",
    "    for p in d['paths']:\n",
    "        img_data, affine = dipy.io.image.load_nifti(p['dwi_path'])\n",
    "        assert((prev_affine_transform is None) or (affine==prev_affine_transform).all())\n",
    "        prev_affine_transform = affine  \n",
    "        bvals, bvecs = dipy.io.read_bvals_bvecs(p['bval_path'], p['bvec_path'])\n",
    "        img_data_list.append(img_data)\n",
    "        bvals_list.append(bvals)\n",
    "        bvecs_list.append(bvecs)\n",
    "        bvals = np.concatenate(bvals_list)\n",
    "    img_data = np.concatenate(img_data_list, axis=-1)\n",
    "    bvecs = np.concatenate(bvecs_list, axis=0)\n",
    "    gtab = dipy.core.gradients.gradient_table(bvals, bvecs)\n",
    "    return img_data, affine, gtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c41a57a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_break = random.choice([d for d in data if len(d['paths'])>1]) # Pick one from the Philips kids\n",
    "d_cts = random.choice([d for d in data if len(d['paths'])==1]) # Pick one from the single-file kids\n",
    "\n",
    "img_data, affine, gtab = load_data(d_break) # Load one to demonstrate how we process it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a292188",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_masked, mask = dipy.segment.mask.median_otsu(img_data, vol_idx = range(img_data.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8600dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[:,:,90].T, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50616013",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model = dipy.reconst.dti.TensorModel(gtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fit = tensor_model.fit(img_data_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to obtain the FA image from the tensor_fit object, here is how to do that\n",
    "fa = dipy.reconst.dti.fractional_anisotropy(tensor_fit.evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(fa).sum() # Notice there are no nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc07182",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
    "axs[0].imshow(fa[62,:,:].T, origin='lower', cmap='gray')\n",
    "axs[1].imshow(fa[:,:,80].T, origin='lower', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lower triangular part, \n",
    "# i.e. the unique elements of the diffusion tensor in the order Dxx, Dxy, Dyy, Dxz, Dyz, Dzz\n",
    "lt = tensor_fit.lower_triangular()\n",
    "dipy.io.image.save_nifti('test_lt.nii.gz', lt, affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781fff3",
   "metadata": {},
   "source": [
    "If you wanted to construct the FA image from the lower triangular part of the diffusion tensor, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da622d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig = dipy.reconst.dti.eig_from_lo_tri(lt) # has eigenvals and eigenvecs\n",
    "eigvals = eig[:,:,:,:3] # take only the eigenvals\n",
    "fa = dipy.reconst.dti.fractional_anisotropy(eigvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3742da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
    "axs[0].imshow(fa[62,:,:].T, origin='lower', cmap='gray')\n",
    "axs[1].imshow(fa[:,:,80].T, origin='lower', cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
